
# Noir â€” Cross-Platform Voice Assistant

Noir is a Python-based, cross-platform voice assistant that works **online and offline**.  
It integrates cloud AI providers (OpenAI, Perplexity) for rich responses when online,  
and uses local models (Ollama, Vosk, Piper) when offline â€” so you always get an answer.

---

## âœ¨ Features
- ğŸ¤ **Speech to Text (STT)**  
  - **Online**: OpenAI Whisper API  
  - **Offline**: Vosk  
- ğŸ’¬ **Conversational AI**  
  - **Online**: OpenAI, Perplexity  
  - **Offline**: Local LLM via Ollama / llama.cpp  
- ğŸ”Š **Text to Speech (TTS)**  
  - **Online**: Microsoft Edge TTS  
  - **Offline**: Piper  
- ğŸ–¥ï¸ **Cross-Platform Clients**  
  - **Desktop**: PySide6 GUI  
  - **Android**: Kivy/KivyMD app  

---

## ğŸ“‚ Project Structure
---
noir/
â”œâ”€ server/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ main.py               # FastAPI entry point
â”‚  â”œâ”€ config.py             # API keys, settings
â”‚  â”œâ”€ routes/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â”œâ”€ assist.py         # /v1/assist (chat logic)
â”‚  â”‚   â”œâ”€ stt.py            # /v1/stt (speech to text)
â”‚  â”‚   â”œâ”€ tts.py            # /v1/tts (text to speech)
â”‚  â”œâ”€ services/
â”‚  â”‚   â”œâ”€ __init__.py
â”‚  â”‚   â”œâ”€ openai_api.py     # Calls to OpenAI
â”‚  â”‚   â”œâ”€ perplexity_api.py # Calls to Perplexity
â”‚  â”‚   â”œâ”€ offline_llm.py    # Local LLM (Ollama, llama.cpp, etc.)
â”‚  â”‚   â”œâ”€ vosk_stt.py       # Offline STT
â”‚  â”‚   â”œâ”€ whisper_stt.py    # OpenAI Whisper API
â”‚  â”‚   â”œâ”€ piper_tts.py      # Offline TTS
â”‚  â”‚   â”œâ”€ edge_tts.py       # Cloud TTS fallback
â”‚  â””â”€ utils/
â”‚      â”œâ”€ audio.py          # Audio processing helpers
â”‚      â”œâ”€ model_selector.py # Picks model based on mode (online/offline)
â”‚
â”œâ”€ client/
â”‚  â”œâ”€ desktop/              # PySide6 GUI app
â”‚  â”‚   â”œâ”€ main.py
â”‚  â”‚   â”œâ”€ ui_main.py
â”‚  â”‚   â”œâ”€ recorder.py
â”‚  â”‚   â”œâ”€ player.py
â”‚  â”‚   â”œâ”€ api_client.py
â”‚  â”‚
â”‚  â”œâ”€ android/              # Kivy/KivyMD mobile app
â”‚  â”‚   â”œâ”€ main.py
â”‚  â”‚   â”œâ”€ recorder.py
â”‚  â”‚   â”œâ”€ player.py
â”‚  â”‚   â”œâ”€ api_client.py
â”‚
â”œâ”€ tests/
â”‚  â”œâ”€ test_assist.py
â”‚  â”œâ”€ test_stt.py
â”‚  â”œâ”€ test_tts.py
â”‚
â”œâ”€ requirements.txt
â”œâ”€ README.md
â”œâ”€ .env.example
â””â”€ run.sh
---
## âš™ï¸ Requirements

### System Dependencies
- **Python 3.10+**
- `ffmpeg` (audio processing)
- **Offline Models** *(optional for offline mode)*:
  - [Vosk model](https://alphacephei.com/vosk/models)
  - [Piper voice model](https://github.com/rhasspy/piper)
  - [Ollama](https://ollama.ai/) or `llama.cpp`

### Python Dependencies
```bash
pip install -r requirements.txt
````

Example `requirements.txt`:

```
fastapi
uvicorn
requests
pydantic
vosk
pyaudio
PySide6
kivy
kivymd
```

---

## ğŸš€ Running Noir

### 1ï¸âƒ£ Backend

```bash
uvicorn server.main:app --reload --port 8000
```

### 2ï¸âƒ£ Desktop Client

```bash
cd client/desktop
python main.py
```

### 3ï¸âƒ£ Android Client

```bash
cd client/android
python main.py
# (or build APK with buildozer)
```

---

## ğŸŒ API Endpoints

| Method | Endpoint     | Description     |
| ------ | ------------ | --------------- |
| POST   | `/v1/stt`    | Speech â†’ Text   |
| POST   | `/v1/assist` | Get AI response |
| POST   | `/v1/tts`    | Text â†’ Speech   |
| GET    | `/`          | Health check    |

---

## ğŸ” Configuration

Copy `.env.example` â†’ `.env` and fill in your keys:

```
OPENAI_API_KEY=your_openai_key
PERPLEXITY_API_KEY=your_perplexity_key
OFFLINE_LLM_BASE_URL=http://localhost:11434
OFFLINE_LLM_MODEL=llama2
```

---

## ğŸ›  Development Notes

* When **offline**, Noir automatically switches to local STT/LLM/TTS.
* Clients and backend communicate over HTTP/WebSocket for real-time interaction.
* Audio formats: `WAV` for STT, `MP3`/`WAV` for TTS.

---

## ğŸ“œ License

MIT License â€” do whatever you want, just keep the credits.

---

## ğŸ“Œ Roadmap

* [ ] Add hotword detection ("Hey Noir")
* [ ] Add browser extension
* [ ] Add knowledge graph integration
* [ ] Improve multi-turn memory


