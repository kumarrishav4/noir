
# Noir â€” Cross-Platform Voice Assistant

Noir is a Python-based, cross-platform voice assistant that works **online and offline**.  
It integrates cloud AI providers (OpenAI, Perplexity) for rich responses when online,  
and uses local models (Ollama, Vosk, Piper) when offline â€” so you always get an answer.

---

## âœ¨ Features
- ğŸ¤ **Speech to Text (STT)**  
  - **Online**: OpenAI Whisper API  
  - **Offline**: Vosk  
- ğŸ’¬ **Conversational AI**  
  - **Online**: OpenAI, Perplexity  
  - **Offline**: Local LLM via Ollama / llama.cpp  
- ğŸ”Š **Text to Speech (TTS)**  
  - **Online**: Microsoft Edge TTS  
  - **Offline**: Piper  
- ğŸ–¥ï¸ **Cross-Platform Clients**  
  - **Desktop**: PySide6 GUI  
  - **Android**: Kivy/KivyMD app  

---

## ğŸ“‚ Project Structure

'''
noir/
â”œâ”€ server/                  # FastAPI backend
â”‚  â”œâ”€ main.py
â”‚  â”œâ”€ config.py
â”‚  â”œâ”€ routes/               # API endpoints
â”‚  â”œâ”€ services/             # STT, TTS, LLM integrations
â”‚  â””â”€ utils/                 # Helpers & model selection
â”œâ”€ client/
â”‚  â”œâ”€ desktop/               # PySide6 GUI
â”‚  â””â”€ android/               # Kivy/KivyMD app
â”œâ”€ tests/                    # Unit tests
â”œâ”€ requirements.txt
â”œâ”€ .env.example
â””â”€ README.md
'''

## âš™ï¸ Requirements

### System Dependencies
- **Python 3.10+**
- `ffmpeg` (audio processing)
- **Offline Models** *(optional for offline mode)*:
  - [Vosk model](https://alphacephei.com/vosk/models)
  - [Piper voice model](https://github.com/rhasspy/piper)
  - [Ollama](https://ollama.ai/) or `llama.cpp`

### Python Dependencies
```bash
pip install -r requirements.txt
````

Example `requirements.txt`:

```
fastapi
uvicorn
requests
pydantic
vosk
pyaudio
PySide6
kivy
kivymd
```

---

## ğŸš€ Running Noir

### 1ï¸âƒ£ Backend

```bash
uvicorn server.main:app --reload --port 8000
```

### 2ï¸âƒ£ Desktop Client

```bash
cd client/desktop
python main.py
```

### 3ï¸âƒ£ Android Client

```bash
cd client/android
python main.py
# (or build APK with buildozer)
```

---

## ğŸŒ API Endpoints

| Method | Endpoint     | Description     |
| ------ | ------------ | --------------- |
| POST   | `/v1/stt`    | Speech â†’ Text   |
| POST   | `/v1/assist` | Get AI response |
| POST   | `/v1/tts`    | Text â†’ Speech   |
| GET    | `/`          | Health check    |

---

## ğŸ” Configuration

Copy `.env.example` â†’ `.env` and fill in your keys:

```
OPENAI_API_KEY=your_openai_key
PERPLEXITY_API_KEY=your_perplexity_key
OFFLINE_LLM_BASE_URL=http://localhost:11434
OFFLINE_LLM_MODEL=llama2
```

---

## ğŸ›  Development Notes

* When **offline**, Noir automatically switches to local STT/LLM/TTS.
* Clients and backend communicate over HTTP/WebSocket for real-time interaction.
* Audio formats: `WAV` for STT, `MP3`/`WAV` for TTS.

---

## ğŸ“œ License

MIT License â€” do whatever you want, just keep the credits.

---

## ğŸ“Œ Roadmap

* [ ] Add hotword detection ("Hey Noir")
* [ ] Add browser extension
* [ ] Add knowledge graph integration
* [ ] Improve multi-turn memory


